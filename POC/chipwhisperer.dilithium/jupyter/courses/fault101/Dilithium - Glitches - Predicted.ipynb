{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilithium - Glitches - Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPETYPE = 'OPENADC'\n",
    "PLATFORM = 'CW308_STM32F4'\n",
    "SS_VER = 'SS_VER_2_1'\n",
    "\n",
    "fw_path = \"../../../hardware/victims/firmware/simpleserial-dilithium-ref/simpleserial-dilithium-ref-{}.hex\".format(PLATFORM)\n",
    "\n",
    "TIMEOUT_SIGN_MS = 640\n",
    "TIMEOUT_SIGN_NS = TIMEOUT_SIGN_MS * 1e6\n",
    "\n",
    "# POLY_INDEX was previously called ITER_TARGET\n",
    "POLY_INDEX = 60  # e.g.: POLY_INDEX = 0 means that a fault is issued after the loop where the index is 0; thus we have 4 non-zero coefficients and 252 zero coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.NOTSET)\n",
    "logging.getLogger('io.github.alex1s.python-dilithium').setLevel(logging.WARNING)\n",
    "logging.getLogger('gurobipy.gurobipy').setLevel(logging.WARNING) # please be quiet gurobi\n",
    "logging.getLogger().setLevel(logging.DEBUG + 1) # default logger should not be used anyways!\n",
    "__LOGGER = logging.getLogger('sigglitches')\n",
    "__LOGGER.setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"usb_ctrl\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '../../../software' not in sys.path:\n",
    "    sys.path.append('../../../software')\n",
    "if 'python-dilithium' not in sys.path:\n",
    "    sys.path.append('python-dilithium')\n",
    "if 'dilithium_solver' not in sys.path:\n",
    "    sys.path.append('dilithium_solver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chipwhisperer as cw\n",
    "import importlib\n",
    "import json\n",
    "import uuid\n",
    "import threading\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from chipwhisperer.capture.targets import TargetIOError, TargetTimeoutError\n",
    "from dilithium import Dilithium\n",
    "import struct\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import functools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "make -C ../../../hardware/victims/firmware/simpleserial-dilithium-ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if not scope.connectStatus:\n",
    "        scope.con()\n",
    "except NameError:\n",
    "    scope = cw.scope()\n",
    "\n",
    "target = cw.target(scope, cw.targets.SimpleSerial2Dilithium)\n",
    "#target.baud = 230400\n",
    "target.scope = scope\n",
    "target.con()\n",
    "\n",
    "time.sleep(0.05)\n",
    "target.dglitch_settings()  # dilithium glitch settings\n",
    "\n",
    "d = target.dilithium\n",
    "\n",
    "print(\"INFO: Found ChipWhispererðŸ˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line to program the firmware; this takes a little while ...\n",
    "# cw.program_target(scope, cw.programmers.STM32FProgrammer, fw_path)\n",
    "target.reboot_flush()  # make sure the target is up and running for seamless future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    def __init__(self):\n",
    "        self.__messages = []\n",
    "        self.__signatures = []\n",
    "        self.__signatures_no_fault = []\n",
    "        \n",
    "        def get_message_without_rejections(poly_index: int = None) -> (bytes, bytes):\n",
    "            \"\"\"Returns message, signature_packed\"\"\"\n",
    "            if poly_index is None:\n",
    "                poly_index = 1000  # this index is out of range thus it will not fault\n",
    "            for i in range(2 ** 16 - 1):\n",
    "                upper = i // 256\n",
    "                lower = i % 256\n",
    "                message = bytes([upper, lower])\n",
    "                # __LOGGER.debug(f'Checking whether message {message}, faulted at polyvec_index \"0\" and poly_index \"{poly_index}\",  will sign without rejections ...')\n",
    "                signature_packed, num_rejections = d.signature_faulted(message, target.secret_key, 0, poly_index)\n",
    "                if num_rejections != 0:\n",
    "                    message = None\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            if message is None:\n",
    "                raise RuntimeException('We did not find a message without rejections searching two full bytes. While theoretically possible, it is more likely that the \"signature_faulted\" implementation is wrong.')\n",
    "            return message, signature_packed\n",
    "        \n",
    "        for poly_index in range(0, d._polyz_unpack_num_iters):  # faulted at index _polyz_unpack_num_iters - 1 would mean no fault, because at that point in time all 256 coefficients already have been sampled\n",
    "            message, signature = get_message_without_rejections(poly_index)\n",
    "            self.__messages.append(message)\n",
    "            self.__signatures.append(signature)\n",
    "            self.__signatures_no_fault.append(d.signature(message, target.secret_key))\n",
    "        assert len(set(self.__signatures)) == len(self.__signatures)\n",
    "    \n",
    "    def get_message_no_fault(self) -> bytes:\n",
    "        return self.__messages[-1]\n",
    "    \n",
    "    def get_signature_no_fault(self) -> bytes:\n",
    "        return self.__signatures[-1]\n",
    "\n",
    "    def get_message_faulted(self, poly_index: int)  -> bytes:\n",
    "        assert 0 <= poly_index < d._polyz_unpack_num_iters - 1\n",
    "        return self.__messages[poly_index]\n",
    "    \n",
    "    def get_signature_faulted(self) -> bytes:\n",
    "        assert 0 <= poly_index < d._polyz_unpack_num_iters - 1\n",
    "        return self.__signatures[poly_index]\n",
    "    \n",
    "    def get_signature_faulted(self) -> bytes:\n",
    "        assert 0 <= poly_index < d._polyz_unpack_num_iters - 1\n",
    "        return self.__signatures[poly_index]\n",
    "    \n",
    "    def match(self, signature_packed: bytes) -> int:\n",
    "        \"\"\"\n",
    "        Check if a signatures matches with a prediction.\n",
    "        \n",
    "        Returns -1 if it did not match with any prediction.\n",
    "        Returns d._polyz_unpack_num_iters -1 if it matches the non-faulted prediction.\n",
    "        Otherwise the return value i indicates that it matches the prediction of a fault\n",
    "        after i + 1 iteration(s) / non-zero coefficient(s).\n",
    "        \"\"\"\n",
    "        # first check if it is not faulted\n",
    "        try:\n",
    "            self.__signatures_no_fault.index(signature_packed)\n",
    "            return d._polyz_unpack_num_iters - 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # see if it matches a expected fault pattern of any poly_index\n",
    "        try:\n",
    "            return self.__signatures.index(signature_packed)\n",
    "        except ValueError:\n",
    "            return -1\n",
    "        \n",
    "predictions = Predictions()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these predictions are only needed when atting the loop\n",
    "# poly_predictuons[i] = poly we would expect if faulted after iteration with _index_ i\n",
    "target.loop()\n",
    "poly_packed_no_fault = target.get_poly()\n",
    "poly_no_fault = d._polyz_unpack(poly_packed_no_fault)\n",
    "poly_predictions = []\n",
    "for i in range(d._polyz_unpack_num_iters):\n",
    "    split = (i + 1) * d._polyz_unpack_coeffs_per_iter\n",
    "    poly_fault = np.concatenate((poly_no_fault[:split], np.zeros(d.n - split, dtype=np.int32)))\n",
    "    assert np.shape(poly_fault) == (d.n,)\n",
    "    poly_predictions.append(d._polyz_pack(poly_fault))\n",
    "\n",
    "print(f\"trig_count_loop = {target.loop_duration}; trig_count_loop_no_fault = {target.loop_duration_threshold}\")\n",
    "print(f'If we are running the extreme version per iteration the trigger is high for {target.loop_duration / 64} clock cycles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class AttackTarget(Enum):\n",
    "    POLYZ_UNPACK = 'POLYZ_UNPACK'\n",
    "    SIGNATURE = 'SIGNATURE'\n",
    "attack_target = AttackTarget.POLYZ_UNPACK\n",
    "attack_target.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "def analyze_poly(subject: Union[np.ndarray, bytes], reference: Union[np.ndarray, bytes]) -> (Union[int, None], Union[int, None]):\n",
    "    \"\"\"\n",
    "    Analyze the possibly faulted poly (subject) to a non-faulted (reference) one.\n",
    "    \n",
    "    Returns a pair of None if subject and reference do not differ.\n",
    "    Otherwise the first integer of the pair is the number of leading coefficients which are the same\n",
    "    and the second integer is the number of trailing zeros of the subject.\n",
    "    \"\"\"\n",
    "    if type(subject) == bytes:\n",
    "        subject = d._polyz_unpack(subject)\n",
    "    if type(reference) == bytes:\n",
    "        reference = d._polyz_unpack(reference)\n",
    "    \n",
    "    for i in range(d.n):\n",
    "        if reference[i] != subject[i]:\n",
    "            num_leading_same = i\n",
    "            break\n",
    "    else:  # all are the same\n",
    "        return d.n, 0\n",
    "    \n",
    "    # at least one coefficient is different\n",
    "    for i in range(num_leading_same, d.n):\n",
    "        subject_trail = subject[i:]\n",
    "        zeros =  np.zeros(np.shape(subject_trail))\n",
    "        if np.all(subject_trail == zeros):\n",
    "            return num_leading_same, np.shape(zeros)[0] \n",
    "        \n",
    "    return num_leading_same, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_estimate_zeros(z: np.ndarray) -> int:\n",
    "    np.sum(np.abs(z) <= d.beta)\n",
    "\n",
    "def sign_get_same_and_zero(z: np.ndarray) -> int:\n",
    "    estimated_zeros = sign_estimate_zeros(z)\n",
    "    estimated_same = d.n - estimated_zeros\n",
    "    return estimated_same, estimated_zeros\n",
    "\n",
    "def sign_action() -> None:\n",
    "    pass\n",
    "    #message_int = 0\n",
    "    #try:\n",
    "    #    target.sign(bytes([message_int], timeout=TIMEOUT_SIGN_MS)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell defines all the functions and constants needed for one_try\n",
    "get_index = lambda num_leading_same, num_trailing_zero: num_leading_same - num_leading_same % d._polyz_unpack_coeffs_per_iter\n",
    "if attack_target == AttackTarget.POLYZ_UNPACK:\n",
    "    action = target.loop\n",
    "    get_result_packed = target.get_poly\n",
    "    trig_count_threshold = target.loop_duration_threshold\n",
    "    unpack_result = d._polyz_unpack\n",
    "    get_same_and_zero = lambda poly_faulted: analyze_poly(poly_faulted, poly_no_fault)\n",
    "    predictions = target.signature_predictions\n",
    "    get_new_zeros = lambda poly: np.array((np.sum(poly == 0),) + (0,) * (d.l - 1))\n",
    "    normal_trig_count = target.loop_duration\n",
    "else:\n",
    "    action = functools.partial(target.sign, timeout=TIMEOUT_SIGN_MS)\n",
    "    get_result_packed = target.get_sig\n",
    "    trig_count_threshold = target.loop_duration_sign_threshold\n",
    "    unpack_result = lambda sig_packed: d._unpack_sig(sig_packed)[1]  # return z\n",
    "    get_same_and_zero = sign_get_same_and_zero\n",
    "    predictions = target.signature_predictions\n",
    "    get_new_zeros = lambda z: np.sum(np.abs(z) <= d.beta, axis=1)\n",
    "    normal_trig_count = target.loop_duration_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glitch_spots = [ITER_TARGET * 62 - 73]\n",
    "# line above should be equivalent to ITER_TARGET * 62 + 51\n",
    "# lets think about the previous line: offset of 51 can not be a proper offset to fault as an iteration takes 62 clokc cycles\n",
    "# and the first one takes a few cycles longer as it has to return from the trigger_high function and setup the loop\n",
    "# thus we first valid offset has to be 51 + 61 = 112;\n",
    "# the forumlar we need to use right now with POLY_INDEX is thus POLY_INDEX * 62 + 51\n",
    "# with POLY_INDEX in [0, 1, ..., 62]\n",
    "# width_start = 6.640625\n",
    "\n",
    "# be aware that a iteration = poly_index + 1 or iteration - 1 = poly_index\n",
    "\n",
    "# duration is 4699 for loop, but for sign it is way lower; it is: ????\n",
    "# thus a iteration is at most 4699 / 64 = 74 for loop and ???? / 64 = ?? for sign\n",
    "\n",
    "# following params caused 128 zeros:\n",
    "#      ext_offset, offset, width\n",
    "#      (2322, -3.515625, 0.78125) (2322, -2.34375, 2.734375)  (2322, 0.390625, 0.390625) (2322, 0.390625, 1.5625)\n",
    "# (2322, 0.390625, 1.5625) has .727272 success rate ('num_leading_same': 124, 'num_trailing_zero': 128,)\n",
    "# all meaningful results I found so far had a _very_ small offset and width, at most 15 but most of the times lower than 2\n",
    "\n",
    "ext_offset_center = normal_trig_count // 2\n",
    "single_loop_iteration_duration = math.ceil(target.loop_duration / d._polyz_unpack_num_iters)\n",
    "half_single_loop_iteration_duration = math.ceil(target.loop_duration / d._polyz_unpack_num_iters / 2)\n",
    "ext_offset_start = ext_offset_center - half_single_loop_iteration_duration\n",
    "ext_offset_stop = ext_offset_center + half_single_loop_iteration_duration\n",
    "print(f\"A loop takes {target.loop_duration} clock cycles, thus we will hit a branch/compare instruction if we search through at least {2 * half_single_loop_iteration_duration} ext_offsets.\")\n",
    "\n",
    "\n",
    "offset_start = 0\n",
    "offset_stop = 20\n",
    "\n",
    "width_start = 0\n",
    "width_stop = 20\n",
    "\n",
    "if attack_target == AttackTarget.POLYZ_UNPACK:\n",
    "    RES_FNAME = f'gc.results.pickled.shortcable-allinbuttight-repeat4-cacheon-{uuid.uuid4()}.json'\n",
    "    \n",
    "    ext_offset_start = 0\n",
    "    ext_offset_stop = single_loop_iteration_duration + 1\n",
    "    \n",
    "    width_start = 0\n",
    "    width_stop = 49.609375\n",
    "    offset_start = -44.921875\n",
    "    offset_stop = 49.609375\n",
    "\n",
    "repeat = 4  # how often to glitch (in consecutive clock cycles)\n",
    "redo = 10  # with a redo of e.g. 10 we find glitches with reliability >= 10%, right?\n",
    "\n",
    "widths = target.widths_which_include(width_start, width_stop)\n",
    "offsets = target.offsets_which_include(offset_start, offset_stop)\n",
    "ext_offsets = list(range(ext_offset_start, ext_offset_stop + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uncomment following block if you want to search from the middle to the outside\n",
    "\n",
    "#a =  ext_offsets[:len(ext_offsets) // 2][::-1]\n",
    "#b =  ext_offsets[len(ext_offsets) // 2:]\n",
    "#res = [None] * len(ext_offsets)\n",
    "#res[1::2] = a\n",
    "#res[::2] = b\n",
    "#ext_offsets = res\n",
    "\n",
    "ext_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_time = len(widths) * len(offsets) * len(ext_offsets) * (redo + 1)\n",
    "print(normal_time)\n",
    "t = TIMEOUT_SIGN_MS * normal_time / 1000\n",
    "print(f'Expected sig time: {t}s = {t/60}min = {t/3600}h')\n",
    "t_all = t * 1.36 # what was that exactly again?\n",
    "print(f'Expected sig + transfer time: {t_all}s = {t_all/60}min = {t_all/3600}h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import chipwhisperer.common.results.glitch as glitch\n",
    "gc = glitch.GlitchController(groups=[\"reset\", \"trig_cnt_high\", \"normal\", \"predicted\", \"zeros\", \"somefault\"], parameters=[\"ext_offset\", \"offset\", \"width\"])\n",
    "gc.set_range(\"width\", min(widths), max(widths))\n",
    "gc.set_range(\"offset\", min(offsets), max(offsets))\n",
    "gc.set_range(\"ext_offset\", min(ext_offsets), max(ext_offsets))\n",
    "# gc.display_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIN_ZEROS = d.n *  2 # double to account for false positive classifications; may still be too little for late glitches\n",
    "#zeros = np.zeros(d.l)\n",
    "#zero_widgets = list((widgets.IntSlider(\n",
    "#    value=0,\n",
    "#    min=0,\n",
    "#    max=MIN_ZEROS + d.n, # most of the time we get a few more\n",
    "#    step=1,\n",
    "#    description=f\"zeros[{i}]\",\n",
    "#    disabled=True,\n",
    "#    continuous_update=True,\n",
    "#    orientation='horizontal',\n",
    "#    readout=True) for i in range(d.l)))\n",
    "#print(f'We need at least {MIN_ZEROS} zeros.')\n",
    "#display(*zero_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs_faulted = []\n",
    "sigs_faulted_params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.reboot_flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for attacking loops isolated\n",
    "def one_try_new(param_tuple, recurse: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Try one fault parameter set.\n",
    "\n",
    "    :param param_tuple: the parameters of the glitch (ext_offset, offset, width)\n",
    "    :param action: what action is going to be glitched (polyz_unpack or signature)\n",
    "    :param get_result_packed: callable \n",
    "    :returns: an upper bound on new zero coefficients\n",
    "    \"\"\"\n",
    "    new_zeros = np.zeros(d.l)\n",
    "    scope.sc.arm(False)  # reset trig_count\n",
    "    scope.arm()\n",
    "    try:\n",
    "        action()\n",
    "    except TargetIOError:  # corrupted or no response from the target; we could but do not really care to differentiate\n",
    "        gc_add(\"reset\", param_tuple)\n",
    "        target.reboot_flush()\n",
    "        return new_zeros\n",
    "    \n",
    "    trig_count = scope.adc.trig_count\n",
    "    metadata = {\"trig_count\": trig_count}\n",
    "    \n",
    "    if trig_count > trig_count_threshold:  # trigger was high too long; _very_ likely no loop abort\n",
    "        gc_add(\"trig_cnt_high\", param_tuple)\n",
    "        return new_zeros\n",
    "    \n",
    "    # if you land here, _very_ likely it was some kind of loop abort\n",
    "    \n",
    "    packed = get_result_packed()\n",
    "    metadata[\"packed\"] = packed\n",
    "    unpacked = unpack_result(packed)\n",
    "    metadata[\"unpacked\"] = unpacked\n",
    "    num_leading_same, num_trailing_zero = get_same_and_zero(unpacked)\n",
    "    metadata[\"num_leading_same\"] = num_leading_same\n",
    "    metadata[\"num_trailing_zero\"] = num_trailing_zero\n",
    "\n",
    "    new_zeros = get_new_zeros(unpacked)\n",
    "    metadata[\"index\"] = get_index(num_leading_same, num_trailing_zero)\n",
    "    \n",
    "    def get_stats(group: str, do_reset: bool = False) -> None:\n",
    "        if not recurse:  # avoid infinite recursion\n",
    "            return\n",
    "        if results_grouped[param_tuple][group] != 1:  # only get stats once per parameter set\n",
    "            return\n",
    "        for _ in range(100):\n",
    "            one_try_new(param_tuple, recurse=False)\n",
    "    \n",
    "    check_next_called = False\n",
    "    def check_next() -> None:\n",
    "        check_next_called = True\n",
    "        if not recurse:\n",
    "            return\n",
    "        __LOGGER.info(f\"Checking next for parameters {param_tuple} ...\")\n",
    "        for i in range(target.loop_duration + 1):\n",
    "            new_ext_offset = i\n",
    "            target.scope.glitch.ext_offset = new_ext_offset\n",
    "            new_params = (new_ext_offset,) + param_tuple[1:]\n",
    "            for _ in range(redo + 1):\n",
    "                one_try_new(new_params, recurse=False)\n",
    "        target.scope.glitch.ext_offset = param_tuple[0]  # restore ext_offset, just in case ...\n",
    "        __LOGGER.info(f\"Done! {param_tuple} ...\")\n",
    "    \n",
    "    prediction = predictions.get(packed)\n",
    "    metadata['prediction'] = prediction\n",
    "    if prediction is not None and prediction == d._polyz_unpack_num_iters - 1:\n",
    "        gc_add(\"normal\", param_tuple, metadata=metadata)\n",
    "    elif prediction is not None and prediction != d._polyz_unpack_num_iters - 1:\n",
    "        gc_add(\"perfect\", param_tuple, metadata=metadata)\n",
    "        get_stats(\"perfect\")\n",
    "        if not check_next_called:\n",
    "            check_next()\n",
    "        check_next_called = True\n",
    "    elif num_trailing_zero >= d._polyz_unpack_coeffs_per_iter:\n",
    "        gc_add(\"zeros\", param_tuple, metadata=metadata)\n",
    "        target.reboot_flush()  # we do not know what happened, better reset\n",
    "        get_stats(\"zeros\", do_reset=True)\n",
    "        if not check_next_called:\n",
    "            check_next()\n",
    "        check_next_called = True\n",
    "    elif prediction == d._polyz_unpack_num_iters - 1:\n",
    "        gc_add(\"normal\", param_tuple, metadata=metadata)\n",
    "    else:\n",
    "        gc_add(\"somefault\", param_tuple, metadata=metadata) # we do not know what happened, better reset\n",
    "        target.reboot_flush()\n",
    "\n",
    "    return new_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results():\n",
    "    with open(RES_FNAME, 'wb') as f:\n",
    "        pickle.dump(gc.results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_lock = threading.Lock()\n",
    "def gc_add(group: str, params: tuple, metadata=None) -> None:\n",
    "    with gc_lock:\n",
    "        try:\n",
    "            gc.add(group, params, metadata)\n",
    "        except TypeError:  # will be raised if we do not \"gc.display_stats\"; but not a problem: still collects all data\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_thread_event = threading.Event()\n",
    "def save_thread() -> None:\n",
    "    while True:\n",
    "        if save_thread_event.is_set():\n",
    "            break\n",
    "        with gc_lock:\n",
    "            save_results()\n",
    "        time.sleep(2 * 60)  # two minutes\n",
    "        \n",
    "thread = threading.Thread(target=save_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thread.start()\n",
    "logging.getLogger(\"ChipWhisperer Target\").setLevel(logging.WARNING + 1)  # disable WARNING messages like \"Read timed out: \" or \"Read timed out: WÃ¿+\"\n",
    "\n",
    "start_time = time.time()\n",
    "do_break = False\n",
    "scope.glitch.repeat = repeat\n",
    "for ext_offset in ext_offsets:\n",
    "    scope.glitch.ext_offset = ext_offset\n",
    "    if gc.widget_list_parameter is not None:\n",
    "        gc.widget_list_parameter[gc.parameters.index(\"ext_offset\")].value = ext_offset\n",
    "    for offset in offsets:\n",
    "        scope.glitch.offset = offset\n",
    "        if gc.widget_list_parameter is not None:\n",
    "            gc.widget_list_parameter[gc.parameters.index(\"offset\")].value = offset\n",
    "        for width in widths:\n",
    "            scope.glitch.width = width\n",
    "            if gc.widget_list_parameter is not None:\n",
    "                gc.widget_list_parameter[gc.parameters.index(\"width\")].value = width\n",
    "\n",
    "            param_tuple = ext_offset, offset, width\n",
    "            for _ in range(redo):\n",
    "                # new_zeros = one_try(scope, target, gc, sigs_faulted, sigs_faulted_params)\n",
    "                # new_zeros = one_try_loop(param_tuple, action=target.loop, get_result_packed=target.get_poly)\n",
    "                new_zeros = one_try_new(param_tuple, recurse=False)\n",
    "                # zeros += new_zeros\n",
    "                # for i, zero_widget in enumerate(zero_widgets):\n",
    "                #     zero_widget.value = zeros[i]\n",
    "\n",
    "                # if np.all(zeros > MIN_ZEROS):\n",
    "                #     do_break = True\n",
    "\n",
    "                if do_break:\n",
    "                    break\n",
    "end_time = time.time()\n",
    "total_duration = end_time - start_time\n",
    "print(f'total duration: {total_duration}s {total_duration/60}min {total_duration/3600}h')\n",
    "\n",
    "print(\"Setting event for save thread.\")\n",
    "save_thread_event.set()\n",
    "print(\"Joining with save thread.\")\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exithere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sigs_faulted_unpacked = list(map(lambda sig_packed: d._unpack_sig_full(sig_packed), sigs_faulted))\n",
    "from dilithium_solver.signature import Signature, calculate_c_matrix_np\n",
    "from dilithium_solver.recover_s_1_entry import recover_s_1_entry\n",
    "from dilithium_solver.parameters import Parameters\n",
    "\n",
    "params = Parameters.get_nist_security_level(d.nist_security_level)\n",
    "\n",
    "sigs = list(map(\n",
    "    lambda sig_faulted: Signature(\n",
    "        sig_faulted[1],\n",
    "        sig_faulted[0],\n",
    "        calculate_c_matrix_np(sig_faulted[0], params)\n",
    "    ), sigs_faulted_unpacked))\n",
    "s_1_entry_index = 0\n",
    "\n",
    "\n",
    "s_1 = d._unpack_sk(sk)[4]\n",
    "timeout = 10\n",
    "threshold = d.beta\n",
    "for i in range(len(sigs_faulted_unpacked[0][1])): # long version of saying \"l\"\n",
    "    result = recover_s_1_entry(sigs, i, s_1, params, 142387, timeout, threshold) # this number is not relevant\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scope' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscope\u001b[49m\u001b[38;5;241m.\u001b[39mdis()\n\u001b[1;32m      2\u001b[0m target\u001b[38;5;241m.\u001b[39mdis()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scope' is not defined"
     ]
    }
   ],
   "source": [
    "scope.dis()\n",
    "target.dis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
